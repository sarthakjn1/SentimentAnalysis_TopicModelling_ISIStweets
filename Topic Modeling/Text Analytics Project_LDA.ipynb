{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e5f56e-a72c-4325-b98d-4252d4dbbc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import re\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454dfeb7-4c77-45be-8b0c-08577bb60878",
   "metadata": {},
   "source": [
    "### Topic Modelling for Positive Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3f379c-a31b-43d6-bfcf-2f5cd86df482",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets = pd.read_csv(\"ISIS-Positive tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae9009a3-a232-4155-8f4c-3e11f9d4c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "    # A number of the tweets start with ENGLISH TRANSLATIONS: so we will remove it \n",
    "    tweet = re.sub(r'ENGLISH TRANSLATION:', '', tweet)\n",
    "    # Also strip the tweets of non-alphabetic characters except #\n",
    "    tweet = re.sub(r'[^A-Za-z# ]', '', tweet)\n",
    "    # Remove retweet indicators\n",
    "    tweet = re.sub(r'^[Rr][Tt]\\s@\\w+: ', '', tweet)\n",
    "    tweet = re.sub(r'^[Rr][Tt]\\s+', '', tweet)\n",
    "    # Remove X (Twitter) handles\n",
    "    tweet = re.sub(r'@\\w+', '', tweet) \n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet)\n",
    "    # Remove 'amp'\n",
    "    tweet = re.sub(r'amp', '', tweet)\n",
    "    \n",
    "    words = tweet.strip().split()\n",
    "  \n",
    "    hashtags = [word for word in words if re.match(r'#', word) != None]\n",
    "    words = [word.lower() for word in words if word not in hashtags]\n",
    "\n",
    "    for hashtag in hashtags:\n",
    "        hashtag = re.sub(r'#', '', hashtag)\n",
    "        words_tag = []\n",
    "        current_word = ''\n",
    "        for a in hashtag:\n",
    "            if a.isupper() and current_word != '':\n",
    "                words_tag.append(current_word)\n",
    "                current_word = '' + a.lower()\n",
    "            else:\n",
    "                current_word = current_word + a.lower()\n",
    "        words_tag.append(current_word)\n",
    "        words.extend(words_tag)\n",
    "\n",
    "    # Option 1: Remove stopwords and stem words using porter stemmer\n",
    "    # p_stem = PorterStemmer()\n",
    "    # words = [p_stem.stem(word.lower()) for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "    # Option 2: Remove stopwords and lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    # Remove duplicates\n",
    "    words = list(set(words))\n",
    "\n",
    "    #Removing high frequency custom stop words\n",
    "    words_to_remove = ['al', 'u', 'im', 'pt', 'g', 'k', 'n', 'e', 'b', 'f', 'p', 'abu', 'de', 'la', 'un', 'je', 'il', 'et', '', 'pa', 'c', 'cest', 'le', 'du', 'que', 'sa', 'di', 'tu', 'dans', 'une', \n",
    "                      'avec', 'qui', 'en', 'ce', 'va', 'est']\n",
    "    words = [word for word in words if word not in words_to_remove]\n",
    "\n",
    "    #Correcting words\n",
    "    corrections = {\n",
    "    'isi': 'isis',\n",
    "    'allh': 'allah',\n",
    "    'jihd': 'jihad'\n",
    "}\n",
    "\n",
    "    # Using list comprehension to replace misspelled words\n",
    "    words = [corrections.get(word, word) for word in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac38a2cd-daa2-4c81-98aa-2035412e5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweet_wordlist = [preprocess(tweet) for tweet in positive_tweets['tweets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a771359e-0b9b-4c3d-a30d-10e5c93afc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(positive_tweet_wordlist)\n",
    "dictionary\n",
    "bow = [dictionary.doc2bow(line) for line in positive_tweet_wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b060067-4b20-4a32-bacb-0e89a4490a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eta(eta, dictionary, corp, txt, ntopics, print_topics=True, print_dist=True):\n",
    "    np.random.seed(42) # set the random seed for repeatability\n",
    "    bow = [dictionary.doc2bow(line) for line in corp] # get the bow-format lines with the set dictionary\n",
    "    with (np.errstate(divide='ignore')):  # ignore divide-by-zero warnings\n",
    "        model = gensim.models.ldamodel.LdaModel(\n",
    "            corpus=bow, id2word=dictionary, num_topics=ntopics,\n",
    "            random_state=42, chunksize=100, eta=eta,\n",
    "            eval_every=-1, update_every=1,\n",
    "            passes=150, alpha='auto', per_word_topics=True)\n",
    "    # visuzlize the model term topics\n",
    "    print('Perplexity: {:.2f}'.format(model.log_perplexity(bow)))\n",
    "    if print_topics:\n",
    "        # display the top terms for each topic\n",
    "        for topic in range(ntopics):\n",
    "            print('Topic {}: {}'.format(topic, [dictionary[w] for w,p in model.get_topic_terms(topic, topn=10)]))\n",
    "    # if print_dist:\n",
    "        # display the topic probabilities for each document\n",
    "        # for line,bag in zip(txt,bow):\n",
    "        #     doc_topics = ['({}, {:.1%})'.format(topic, prob) for topic,prob in model.get_document_topics(bag)]\n",
    "        #     print('{} {}'.format(line, doc_topics))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575bd547-6334-4012-ae81-592fc50d4863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the LDA model using pyLDAvis\n",
    "def visualize_lda(model, bow, dictionary, output_file):\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis_data = pyLDAvis.gensim.prepare(model, bow, dictionary)\n",
    "    pyLDAvis.save_html(vis_data, output_file)\n",
    "    pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06251e-4456-407a-8535-f52c974e8edd",
   "metadata": {},
   "source": [
    "#### Unsupervised Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6471eb57-d602-42b5-910a-93b4a0d18ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: -8.02\n",
      "Topic 0: ['alhamdulillah', 'isis', 'people', 'allah', 'time', 'blessing', 'back', 'jazak', 'celebrate', 'muhammad']\n",
      "Topic 1: ['allah', 'love', 'thanks', 'one', 'welcome', 'best', 'interesting', 'thank', 'syria', 'quran']\n",
      "Topic 2: ['allah', 'may', 'beautiful', 'islamic', 'day', 'state', 'make', 'pleased', 'funny', 'reward']\n",
      "Topic 3: ['yes', 'get', 'true', 'please', 'happy', 'make', 'map', 'upon', 'nidalgazaui', 'word']\n",
      "Topic 4: ['amazing', 'back', 'better', 'muslim', 'support', 'sparksofirhabi', 'love', 'also', 'even', 'nice']\n",
      "Topic 5: ['good', 'great', 'see', 'allah', 'video', 'like', 'aleppo', 'unclesamcoco', 'sheikh', 'victory']\n"
     ]
    }
   ],
   "source": [
    "eta = test_eta('auto', dictionary, positive_tweet_wordlist, positive_tweets['tweets'], ntopics=6)\n",
    "bow = [dictionary.doc2bow(line) for line in positive_tweet_wordlist]\n",
    "visualize_lda(eta, bow, dictionary, 'positive_tweets_unsupervisedlda.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd67032-bdfa-46f0-9ac9-93f8132d07e8",
   "metadata": {},
   "source": [
    "#### Semi-Supervised Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c03d0c-4ab9-4231-a939-4b4c9e171964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eta(priors, etadict, ntopics):\n",
    "    eta = np.full(shape=(ntopics, len(etadict)), fill_value=1) # create a (ntopics, nterms) matrix and fill with 1\n",
    "    for word, topic in priors.items(): # for each word in the list of priors\n",
    "        keyindex = [index for index,term in etadict.items() if term==word] # look up the word in the dictionary\n",
    "        if (len(keyindex)>0): # if it's in the dictionary\n",
    "            eta[topic,keyindex[0]] = 1e7  # put a large number in there\n",
    "    eta = np.divide(eta, eta.sum(axis=0)) # normalize so that the probabilities sum to 1 over all topics\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae579a1-fbed-40d1-9a3d-fc0560bbd121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 6.71\n",
      "Topic 0: ['allah', 'people', 'great', 'yes', 'time', 'love', 'alhamdulillah', 'please', 'may', 'sparksofirhabi']\n",
      "Topic 1: ['good', 'one', 'thanks', 'welcome', 'syria', 'better', 'think', 'indeed', 'cool', 'keep']\n",
      "Topic 2: ['allah', 'may', 'beautiful', 'day', 'see', 'islamic', 'state', 'make', 'victory', 'pleased']\n",
      "Topic 3: ['good', 'best', 'isis', 'video', 'thank', 'week', 'iraq', 'came', 'great', 'rts']\n",
      "Topic 4: ['love', 'back', 'amazing', 'muslim', 'allah', 'support', 'akhi', 'new', 'interesting', 'even']\n"
     ]
    }
   ],
   "source": [
    "apriori_original = {\n",
    "    'love': 0, 'good': 0, 'great': 0, 'best': 0, 'amazing': 0,\n",
    "    'victory': 1, 'alhamdulillah': 1, 'interesting': 1, 'support': 1, 'one': 1,\n",
    "    'help': 2, 'beautiful': 2, 'better': 2, 'thanks': 2, 'day': 2,\n",
    "    'back': 3, 'new': 3, 'video': 3, 'iraq': 3, 'state': 3\n",
    "}\n",
    "eta = create_eta(apriori_original, dictionary, 5)\n",
    "eta = test_eta(eta, dictionary, positive_tweet_wordlist, positive_tweets['tweets'], ntopics=5)\n",
    "visualize_lda(eta, bow, dictionary, 'positive_tweets_supervisedlda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a85f1dc-7bbe-4a22-8649-cfc441b54197",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_tweets = pd.read_csv(\"ISIS-Negative tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d029d3d-ae49-4d17-ba20-0bd8719c1fae",
   "metadata": {},
   "source": [
    "### Topic Modelling for Negative Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c2c6c19-6e80-4d97-8793-c57d8d5eebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_tweet_wordlist = [preprocess(tweet) for tweet in negative_tweets['tweets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c21ba6-2da9-4192-86fb-799c9171dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(negative_tweet_wordlist)\n",
    "dictionary\n",
    "bow = [dictionary.doc2bow(line) for line in negative_tweet_wordlist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762087f9-02a1-4f3d-9d1a-84e5a0a39e7a",
   "metadata": {},
   "source": [
    "#### Unsupervised LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "449f84da-82f1-4975-937e-f0576053825d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: -8.41\n",
      "Topic 0: ['killed', 'syria', 'army', 'iraqi', 'soldier', 'amaq', 'agency', 'force', 'near', 'breaking']\n",
      "Topic 1: ['rebel', 'village', 'killing', 'warreporter', 'police', 'terrorist', 'apostate', 'ypg', 'coalition', 'body']\n",
      "Topic 2: ['people', 'scotsmaninfidel', 'elevn', 'texanna', 'bombing', 'sassysassyred', 'spicylatte', 'death', 'like', 'allah']\n",
      "Topic 3: ['islamic', 'state', 'today', 'attack', 'aleppo', 'isis', 'airstrikes', 'area', 'militant', 'shiite']\n"
     ]
    }
   ],
   "source": [
    "eta = test_eta('auto', dictionary, negative_tweet_wordlist, negative_tweets['tweets'], ntopics=4)\n",
    "visualize_lda(eta, bow, dictionary, 'negative_tweets_unsupervisedlda.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ded0c-9f7d-468b-b6c1-bb38232e5d8b",
   "metadata": {},
   "source": [
    "#### Supervised LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f614ca43-6499-45c3-967f-c75f24b74476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: -2.09\n",
      "Topic 0: ['people', 'muslim', 'warreporter', 'bombing', 'allah', 'terrorist', 'dont', 'layer', 'take', 'know']\n",
      "Topic 1: ['scotsmaninfidel', 'texanna', 'elevn', 'spicylatte', 'sassysassyred', 'like', 'pig', 'kafirkaty', 'saudi', 'year']\n",
      "Topic 2: ['killed', 'syria', 'army', 'iraqi', 'soldier', 'amaq', 'agency', 'islamic', 'state', 'today']\n"
     ]
    }
   ],
   "source": [
    "apriori_original = {\n",
    "    'killed': 0, 'syria': 0, 'army': 0, 'bombing': 0, 'fighters': 0,\n",
    "    'allah': 1, 'jihad': 1, 'faith': 1, 'martyr': 1, 'sharia': 1,\n",
    "    'us': 2, 'west': 2, 'aleppo': 2, 'iraqi': 2, 'policy': 2\n",
    "}\n",
    "eta = create_eta(apriori_original, dictionary, 3)\n",
    "eta = test_eta(eta, dictionary, negative_tweet_wordlist, negative_tweets['tweets'], ntopics=3)\n",
    "visualize_lda(eta, bow, dictionary, 'negative_tweets_supervisedlda.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dffa1c-ece2-4a0b-91ea-5470eb190a77",
   "metadata": {},
   "source": [
    "### Topic Modelling for Neutral Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8538c28f-20af-432e-9b03-7973b1fe1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_tweets = pd.read_csv(\"ISIS-Neutral tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc34918e-50b1-4468-998f-ce819010a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_tweet_wordlist = [preprocess(tweet) for tweet in neutral_tweets['tweets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53e17f04-7ee0-465a-85d6-653114c2b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(neutral_tweet_wordlist)\n",
    "dictionary\n",
    "bow = [dictionary.doc2bow(line) for line in neutral_tweet_wordlist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c8828f-9713-4ada-9978-d14fc29c873b",
   "metadata": {},
   "source": [
    "#### Unsupervised LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e4743e6-9e33-4329-9a16-b35865327140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: -9.35\n",
      "Topic 0: ['allah', 'homs', 'muslim', 'mosul', 'sparksofirhabi', 'scotsmaninfidel', 'time', 'support', 'spicylatte', 'advance']\n",
      "Topic 1: ['wilayat', 'isis', 'northern', 'new', 'say', 'warreporter', 'libya', 'regime', 'palmyra', 'people']\n",
      "Topic 2: ['syria', 'agency', 'amaq', 'breaking', 'army', 'aleppo', 'force', 'fighter', 'near', 'iraq']\n",
      "Topic 3: ['islamic', 'state', 'city', 'control', 'area', 'village', 'day', 'fight', 'group', 'one']\n"
     ]
    }
   ],
   "source": [
    "eta = test_eta('auto', dictionary, neutral_tweet_wordlist, neutral_tweets['tweets'], ntopics=4)\n",
    "visualize_lda(eta, bow, dictionary, 'neutral_tweets_unsupervisedlda.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085ecdc-8508-43b7-8f5d-90c8dc8b4a70",
   "metadata": {},
   "source": [
    "#### Supervised LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4db2935d-79a3-4487-b103-9dc857068c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: -5.26\n",
      "Topic 0: ['islamic', 'state', 'syria', 'wilayat', 'agency', 'amaq', 'breaking', 'army', 'aleppo', 'force']\n",
      "Topic 1: ['isis', 'ramiallolah', 'new', 'say', 'muslim', 'warreporter', 'fight', 'one', 'sparksofirhabi', 'people']\n",
      "Topic 2: ['allah', 'scotsmaninfidel', 'spicylatte', 'elevn', 'sassysassyred', 'texanna', 'may', 'kafirkaty', 'back', 'peigneacheveux']\n"
     ]
    }
   ],
   "source": [
    "apriori_original = {\n",
    "    'islamic': 0, 'city': 0, 'video': 0, 'near': 0, 'attack': 0,\n",
    "    'city': 1, 'new': 1, 'ramiallolah': 1, 'one': 1,\n",
    "    'fighters': 2, 'rebels': 2, 'forces': 2, 'attack': 2 \n",
    "}\n",
    "eta = create_eta(apriori_original, dictionary, 3)\n",
    "eta = test_eta(eta, dictionary, neutral_tweet_wordlist, neutral_tweets['tweets'], ntopics=3)\n",
    "visualize_lda(eta, bow, dictionary, 'neutral_tweets_supervisedlda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353b904-0b1d-47f5-9d5f-de2d97911a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim_env",
   "language": "python",
   "name": "gensim_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
